{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import pickle as pk\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from cleantext import clean\n",
    "import re\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train = pd.read_csv(\"/home/msc2/dbpedia/dbpedia_csv/train.csv\")\n",
    "total_test = pd.read_csv(\"/home/msc2/dbpedia/dbpedia_csv/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14    40000\n",
       "13    40000\n",
       "12    40000\n",
       "11    40000\n",
       "10    40000\n",
       "9     40000\n",
       "8     40000\n",
       "7     40000\n",
       "6     40000\n",
       "5     40000\n",
       "4     40000\n",
       "3     40000\n",
       "2     40000\n",
       "1     40000\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_train[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This shows that the entire data set is properly balanced and does not require any other preprocessing for balancing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train = total_train[\"Content\"]\n",
    "y_train = total_train[\"Class\"]\n",
    "x_test = total_test[\"Content\"]\n",
    "y_test = total_test[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### The following function gets the tf-idf scores of the entire vocabulary omitting the stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words= 'english', sublinear_tf= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The below statement learns the vocabulary of the given training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_fitted = tfidf.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The below statement returns a tf-idf scores of the entire vocabulary in the training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_scores = tfidf_fitted.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<560000x669038 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13695374 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All the chosen models have been trained on the tf-idf scores obtained on the training data set and are tested on tf-idf of test data consisting of 1000 datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    0.1651357142857143\n",
      "10    0.23315357142857143\n",
      "15    0.2663410714285714\n",
      "20    0.3030839285714286\n",
      "25    0.36097678571428576\n",
      "30    0.4064660714285714\n",
      "35    0.4414160714285714\n",
      "40    0.4858339285714285\n",
      "45    0.4854428571428572\n",
      "50    0.5353714285714286\n",
      "55    0.5515857142857142\n",
      "60    0.5531214285714287\n",
      "65    0.5934339285714285\n",
      "70    0.6250214285714286\n",
      "75    0.6259392857142857\n",
      "80    0.6388517857142857\n",
      "85    0.6142\n",
      "90    0.6356839285714286\n",
      "95    0.6565267857142857\n",
      "100    0.6945857142857144\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(1,21):\n",
    "    \n",
    "    clf_rf = RandomForestClassifier(max_depth=3,n_estimators= i*5)\n",
    "    #clf_rf.fit(tfidf_scores,y_train)\n",
    "    print(i*5,\"  \" ,np.mean(cross_val_score(clf_rf,tfidf_scores,y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the above cross validation i have swept from 5 trees to 100 trees and found the validation accuracy incresing along the line of increse of number of trees. All the while i have fixed the depth of trees to be 3, the default value of the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    0.4067071428571428\n",
      "2    0.6020535714285715\n",
      "3    0.6796821428571429\n",
      "4    0.7212928571428572\n",
      "5    0.7548785714285714\n",
      "6    0.7999642857142857\n",
      "7    0.8243750000000001\n",
      "8    0.8301589285714286\n",
      "9    0.8473267857142857\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(1,10):\n",
    "    \n",
    "    clf_rf = RandomForestClassifier(max_depth=i,n_estimators= 100)\n",
    "    #clf_rf.fit(tfidf_scores,y_train)\n",
    "    print(i,\"  \" ,np.mean(cross_val_score(clf_rf,tfidf_scores,y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the above cross validation done for finding the best value for the depth of trees it is clearly seen that the validation accuracy keeps increasing with the increase of number of trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally i have taken 200 chosen trees with with depth 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=15, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf = RandomForestClassifier(max_depth= 15,n_estimators= 200)\n",
    "clf_rf.fit(tfidf_scores,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = tfidf_fitted.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9076"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf.score(test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf_rf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_prob = clf_rf.predict_proba(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Have used the roc_auc score to evaluate the models performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.991612305934066"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_true= y_test,y_score= score_prob,multi_class= 'ovo' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm  = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm.fit(tfidf_scores,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9811142857142857"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm.score(test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:  Since a Linear classifier such as SVM is performing better than the Random Forests which are prominently non-linear it may be the case that the considered data is linearly classifiable  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf_svm.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since probability values are not available for the SVM model could not get the roc_auc score for it. Though its possible to get the probability values by using paltt's scaling; will be working on it post this submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
